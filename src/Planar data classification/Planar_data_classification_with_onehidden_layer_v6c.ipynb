{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "neural-networks-deep-learning",
      "graded_item_id": "wRuwL",
      "launcher_item_id": "NI888"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Planar_data_classification_with_onehidden_layer_v6c.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gbaD7b5Nv_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c6f74c3-0f9d-4284-e788-caad166fa15b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce5N5jIfNx3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0475d22-4f85-4863-ec8d-31c2df7ceaf0"
      },
      "source": [
        "cd '/content/drive/My Drive/DeepLearning/2 Planar Data Classification'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1uyhPMbrsJ4LuUSBDSc3t8GAymf7Z6vWm/2 Planar Data Classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-hV8NiwEonl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgC14p-6Nx8F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69f2ab69-a696-40fa-ce84-83b520e65c3b"
      },
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1uyhPMbrsJ4LuUSBDSc3t8GAymf7Z6vWm/2 Planar Data Classification\n",
            " images\t\t\t\t\t\t\t     planar_utils.py\n",
            "'Planar data classification with a hidden layer.pdf'\t     __pycache__\n",
            " Planar_data_classification_with_onehidden_layer_v6c.ipynb   testCases_v2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tive que trazer os códigos externos para dentro desse notebook, por algum motivo ele não estava reconhecendo:"
      ],
      "metadata": {
        "id": "VijgkWPQCT9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Planar_utils.py"
      ],
      "metadata": {
        "id": "UP5y_PCoCKSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "import sklearn.linear_model\n",
        "\n",
        "def plot_decision_boundary(model, X, y):\n",
        "    # Set min and max values and give it some padding\n",
        "    x_min, x_max = X[0, :].min() - 1, X[0, :].max() + 1\n",
        "    y_min, y_max = X[1, :].min() - 1, X[1, :].max() + 1\n",
        "    h = 0.01\n",
        "    # Generate a grid of points with distance h between them\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    # Predict the function value for the whole grid\n",
        "    Z = model(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    # Plot the contour and training examples\n",
        "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
        "    plt.ylabel('x2')\n",
        "    plt.xlabel('x1')\n",
        "    plt.scatter(X[0, :], X[1, :], c=y, cmap=plt.cm.Spectral)\n",
        "    \n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"\n",
        "    Compute the sigmoid of x\n",
        "\n",
        "    Arguments:\n",
        "    x -- A scalar or numpy array of any size.\n",
        "\n",
        "    Return:\n",
        "    s -- sigmoid(x)\n",
        "    \"\"\"\n",
        "    s = 1/(1+np.exp(-x))\n",
        "    return s\n",
        "\n",
        "def load_planar_dataset():\n",
        "    np.random.seed(1)\n",
        "    m = 400 # number of examples\n",
        "    N = int(m/2) # number of points per class\n",
        "    D = 2 # dimensionality\n",
        "    X = np.zeros((m,D)) # data matrix where each row is a single example\n",
        "    Y = np.zeros((m,1), dtype='uint8') # labels vector (0 for red, 1 for blue)\n",
        "    a = 4 # maximum ray of the flower\n",
        "\n",
        "    for j in range(2):\n",
        "        ix = range(N*j,N*(j+1))\n",
        "        t = np.linspace(j*3.12,(j+1)*3.12,N) + np.random.randn(N)*0.2 # theta\n",
        "        r = a*np.sin(4*t) + np.random.randn(N)*0.2 # radius\n",
        "        X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
        "        Y[ix] = j\n",
        "        \n",
        "    X = X.T\n",
        "    Y = Y.T\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "def load_extra_datasets():  \n",
        "    N = 200\n",
        "    noisy_circles = sklearn.datasets.make_circles(n_samples=N, factor=.5, noise=.3)\n",
        "    noisy_moons = sklearn.datasets.make_moons(n_samples=N, noise=.2)\n",
        "    blobs = sklearn.datasets.make_blobs(n_samples=N, random_state=5, n_features=2, centers=6)\n",
        "    gaussian_quantiles = sklearn.datasets.make_gaussian_quantiles(mean=None, cov=0.5, n_samples=N, n_features=2, n_classes=2, shuffle=True, random_state=None)\n",
        "    no_structure = np.random.rand(N, 2), np.random.rand(N, 2)\n",
        "    \n",
        "    return noisy_circles, noisy_moons, blobs, gaussian_quantiles, no_structure"
      ],
      "metadata": {
        "id": "eZrBHpeoB9JI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#testCases_v2.py"
      ],
      "metadata": {
        "id": "84zcPH4LCPqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def layer_sizes_test_case():\n",
        "    np.random.seed(1)\n",
        "    X_assess = np.random.randn(5, 3)\n",
        "    Y_assess = np.random.randn(2, 3)\n",
        "    return X_assess, Y_assess\n",
        "\n",
        "def initialize_parameters_test_case():\n",
        "    n_x, n_h, n_y = 2, 4, 1\n",
        "    return n_x, n_h, n_y\n",
        "\n",
        "\n",
        "def forward_propagation_test_case():\n",
        "    np.random.seed(1)\n",
        "    X_assess = np.random.randn(2, 3)\n",
        "    b1 = np.random.randn(4,1)\n",
        "    b2 = np.array([[ -1.3]])\n",
        "\n",
        "    parameters = {'W1': np.array([[-0.00416758, -0.00056267],\n",
        "        [-0.02136196,  0.01640271],\n",
        "        [-0.01793436, -0.00841747],\n",
        "        [ 0.00502881, -0.01245288]]),\n",
        "     'W2': np.array([[-0.01057952, -0.00909008,  0.00551454,  0.02292208]]),\n",
        "     'b1': b1,\n",
        "     'b2': b2}\n",
        "\n",
        "    return X_assess, parameters\n",
        "\n",
        "def compute_cost_test_case():\n",
        "    np.random.seed(1)\n",
        "    Y_assess = (np.random.randn(1, 3) > 0)\n",
        "    parameters = {'W1': np.array([[-0.00416758, -0.00056267],\n",
        "        [-0.02136196,  0.01640271],\n",
        "        [-0.01793436, -0.00841747],\n",
        "        [ 0.00502881, -0.01245288]]),\n",
        "     'W2': np.array([[-0.01057952, -0.00909008,  0.00551454,  0.02292208]]),\n",
        "     'b1': np.array([[ 0.],\n",
        "        [ 0.],\n",
        "        [ 0.],\n",
        "        [ 0.]]),\n",
        "     'b2': np.array([[ 0.]])}\n",
        "\n",
        "    a2 = (np.array([[ 0.5002307 ,  0.49985831,  0.50023963]]))\n",
        "    \n",
        "    return a2, Y_assess, parameters\n",
        "\n",
        "def backward_propagation_test_case():\n",
        "    np.random.seed(1)\n",
        "    X_assess = np.random.randn(2, 3)\n",
        "    Y_assess = (np.random.randn(1, 3) > 0)\n",
        "    parameters = {'W1': np.array([[-0.00416758, -0.00056267],\n",
        "        [-0.02136196,  0.01640271],\n",
        "        [-0.01793436, -0.00841747],\n",
        "        [ 0.00502881, -0.01245288]]),\n",
        "     'W2': np.array([[-0.01057952, -0.00909008,  0.00551454,  0.02292208]]),\n",
        "     'b1': np.array([[ 0.],\n",
        "        [ 0.],\n",
        "        [ 0.],\n",
        "        [ 0.]]),\n",
        "     'b2': np.array([[ 0.]])}\n",
        "\n",
        "    cache = {'A1': np.array([[-0.00616578,  0.0020626 ,  0.00349619],\n",
        "         [-0.05225116,  0.02725659, -0.02646251],\n",
        "         [-0.02009721,  0.0036869 ,  0.02883756],\n",
        "         [ 0.02152675, -0.01385234,  0.02599885]]),\n",
        "  'A2': np.array([[ 0.5002307 ,  0.49985831,  0.50023963]]),\n",
        "  'Z1': np.array([[-0.00616586,  0.0020626 ,  0.0034962 ],\n",
        "         [-0.05229879,  0.02726335, -0.02646869],\n",
        "         [-0.02009991,  0.00368692,  0.02884556],\n",
        "         [ 0.02153007, -0.01385322,  0.02600471]]),\n",
        "  'Z2': np.array([[ 0.00092281, -0.00056678,  0.00095853]])}\n",
        "    return parameters, cache, X_assess, Y_assess\n",
        "\n",
        "def update_parameters_test_case():\n",
        "    parameters = {'W1': np.array([[-0.00615039,  0.0169021 ],\n",
        "        [-0.02311792,  0.03137121],\n",
        "        [-0.0169217 , -0.01752545],\n",
        "        [ 0.00935436, -0.05018221]]),\n",
        " 'W2': np.array([[-0.0104319 , -0.04019007,  0.01607211,  0.04440255]]),\n",
        " 'b1': np.array([[ -8.97523455e-07],\n",
        "        [  8.15562092e-06],\n",
        "        [  6.04810633e-07],\n",
        "        [ -2.54560700e-06]]),\n",
        " 'b2': np.array([[  9.14954378e-05]])}\n",
        "\n",
        "    grads = {'dW1': np.array([[ 0.00023322, -0.00205423],\n",
        "        [ 0.00082222, -0.00700776],\n",
        "        [-0.00031831,  0.0028636 ],\n",
        "        [-0.00092857,  0.00809933]]),\n",
        " 'dW2': np.array([[ -1.75740039e-05,   3.70231337e-03,  -1.25683095e-03,\n",
        "          -2.55715317e-03]]),\n",
        " 'db1': np.array([[  1.05570087e-07],\n",
        "        [ -3.81814487e-06],\n",
        "        [ -1.90155145e-07],\n",
        "        [  5.46467802e-07]]),\n",
        " 'db2': np.array([[ -1.08923140e-05]])}\n",
        "    return parameters, grads\n",
        "\n",
        "def nn_model_test_case():\n",
        "    np.random.seed(1)\n",
        "    X_assess = np.random.randn(2, 3)\n",
        "    Y_assess = (np.random.randn(1, 3) > 0)\n",
        "    return X_assess, Y_assess\n",
        "\n",
        "def predict_test_case():\n",
        "    np.random.seed(1)\n",
        "    X_assess = np.random.randn(2, 3)\n",
        "    parameters = {'W1': np.array([[-0.00615039,  0.0169021 ],\n",
        "        [-0.02311792,  0.03137121],\n",
        "        [-0.0169217 , -0.01752545],\n",
        "        [ 0.00935436, -0.05018221]]),\n",
        "     'W2': np.array([[-0.0104319 , -0.04019007,  0.01607211,  0.04440255]]),\n",
        "     'b1': np.array([[ -8.97523455e-07],\n",
        "        [  8.15562092e-06],\n",
        "        [  6.04810633e-07],\n",
        "        [ -2.54560700e-06]]),\n",
        "     'b2': np.array([[  9.14954378e-05]])}\n",
        "    return parameters, X_assess"
      ],
      "metadata": {
        "id": "EulikJbzCDtL"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUEuoDQ-NpPX"
      },
      "source": [
        "# Planar data classification with one hidden layer\n",
        "\n",
        "It's time to build your first neural network, which will have a hidden layer. You will see a big difference between this model and the one you implemented using logistic regression. \n",
        "\n",
        "**You will learn how to:**\n",
        "- Implement a 2-class classification neural network with a single hidden layer\n",
        "- Use units with a non-linear activation function, such as tanh \n",
        "- Compute the cross entropy loss \n",
        "- Implement forward and backward propagation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwDJ1vZ0NpPY"
      },
      "source": [
        "## 1 - Packages ##\n",
        "\n",
        "Let's first import all the packages that you will need during this assignment.\n",
        "- [numpy](https://www.numpy.org/) is the fundamental package for scientific computing with Python.\n",
        "- [sklearn](http://scikit-learn.org/stable/) provides simple and efficient tools for data mining and data analysis. \n",
        "- [matplotlib](http://matplotlib.org) is a library for plotting graphs in Python.\n",
        "- testCases provides some test examples to assess the correctness of your functions\n",
        "- planar_utils provide various useful functions used in this assignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hyjpJYgNpPY"
      },
      "source": [
        "# Package imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from testCases_v2 import *\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "import sklearn.linear_model\n",
        "from planar_utils import plot_decision_boundary, sigmoid, load_planar_dataset, load_extra_datasets\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "np.random.seed(1) # set a seed so that the results are consistent"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo5DC-j5NpPc"
      },
      "source": [
        "## 2 - Dataset ##\n",
        "\n",
        "First, let's get the dataset you will work on. The following code will load a \"flower\" 2-class dataset into variables `X` and `Y`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf36qXc-NpPd"
      },
      "source": [
        "X, Y = load_planar_dataset()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIn_zZB9NpPh"
      },
      "source": [
        "Visualize the dataset using matplotlib. The data looks like a \"flower\" with some red (label y=0) and some blue (y=1) points. Your goal is to build a model to fit this data. In other words, we want the classifier to define regions as either red or blue."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w49jqqnqNpPh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "7b675187-35d2-4fd6-c055-840a0ddc29ac"
      },
      "source": [
        "# Visualize the data:\n",
        "plt.scatter(X[0, :], X[1, :])#, c=Y, s=40, cmap=plt.cm.Spectral);\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'y')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHRvoB1nNpPk"
      },
      "source": [
        "You have:\n",
        "    - a numpy-array (matrix) X that contains your features (x1, x2)\n",
        "    - a numpy-array (vector) Y that contains your labels (red:0, blue:1).\n",
        "\n",
        "Lets first get a better sense of what our data is like. \n",
        "\n",
        "**Exercise**: How many training examples do you have? In addition, what is the `shape` of the variables `X` and `Y`? \n",
        "\n",
        "**Hint**: How do you get the shape of a numpy array? [(help)](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWrIVag-NpPl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a8845fe-4624-4588-a130-e5a150738dc2"
      },
      "source": [
        "### START CODE HERE ### (≈ 3 lines of code)\n",
        "shape_X = X.shape\n",
        "shape_Y = Y.shape\n",
        "m = X.shape[1]  # training set size\n",
        "### END CODE HERE ###\n",
        "\n",
        "print ('The shape of X is: ' + str(shape_X))\n",
        "print ('The shape of Y is: ' + str(shape_Y))\n",
        "print ('I have m = %d training examples!' % (m))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of X is: (2, 400)\n",
            "The shape of Y is: (1, 400)\n",
            "I have m = 400 training examples!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnMKmUZJNpPo"
      },
      "source": [
        "**Expected Output**:\n",
        "       \n",
        "<table style=\"width:20%\">\n",
        "  <tr>\n",
        "    <td>**shape of X**</td>\n",
        "    <td> (2, 400) </td> \n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>**shape of Y**</td>\n",
        "    <td>(1, 400) </td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>**m**</td>\n",
        "    <td> 400 </td> \n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jNof0RSNpPo"
      },
      "source": [
        "## 3 - Simple Logistic Regression\n",
        "\n",
        "Before building a full neural network, lets first see how logistic regression performs on this problem. You can use sklearn's built-in functions to do that. Run the code below to train a logistic regression classifier on the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtcUgImQNpPp"
      },
      "source": [
        "# Train the logistic regression classifier\n",
        "clf = sklearn.linear_model.LogisticRegressionCV();\n",
        "clf.fit(X.T, Y.ravel());"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkYBVwtyNpPs"
      },
      "source": [
        "You can now plot the decision boundary of these models. Run the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "i0uv2R6wNpPs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "7b56a32f-4410-4f0f-f7c4-02433d10cb53"
      },
      "source": [
        "# Plot the decision boundary for logistic regression\n",
        "plot_decision_boundary(lambda x: clf.predict(x), X, Y)\n",
        "plt.title(\"Logistic Regression\")\n",
        "\n",
        "# Print accuracy\n",
        "LR_predictions = clf.predict(X.T)\n",
        "print ('Accuracy of logistic regression: %d ' % float((np.dot(Y,LR_predictions) + np.dot(1-Y,1-LR_predictions))/float(Y.size)*100) +\n",
        "       '% ' + \"(percentage of correctly labelled datapoints)\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of logistic regression: 47 % (percentage of correctly labelled datapoints)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsNxV8dtNpPw"
      },
      "source": [
        "**Expected Output**:\n",
        "\n",
        "<table style=\"width:20%\">\n",
        "  <tr>\n",
        "    <td>**Accuracy**</td>\n",
        "    <td> 47% </td> \n",
        "  </tr>\n",
        "  \n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOKb5iyENpPw"
      },
      "source": [
        "**Interpretation**: The dataset is not linearly separable, so logistic regression doesn't perform well. Hopefully a neural network will do better. Let's try this now! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVn5Sze7NpPx"
      },
      "source": [
        "## 4 - Neural Network model\n",
        "\n",
        "Logistic regression did not work well on the \"flower dataset\". You are going to train a Neural Network with a single hidden layer.\n",
        "\n",
        "**Here is our model**:\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1YHzmgffVa-muqDWUGsU7Qb8oH0X87XO5)\n",
        "\n",
        "**Mathematically**:\n",
        "\n",
        "For one example $x^{(i)}$:\n",
        "$$z^{[1] (i)} =  W^{[1]} x^{(i)} + b^{[1]}\\tag{1}$$ \n",
        "$$a^{[1] (i)} = \\tanh(z^{[1] (i)})\\tag{2}$$\n",
        "$$z^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2]}\\tag{3}$$\n",
        "$$\\hat{y}^{(i)} = a^{[2] (i)} = \\sigma(z^{ [2] (i)})\\tag{4}$$\n",
        "$$y^{(i)}_{prediction} = \\begin{cases} 1 & \\mbox{if } a^{[2](i)} > 0.5 \\\\ 0 & \\mbox{otherwise } \\end{cases}\\tag{5}$$\n",
        "\n",
        "Given the predictions on all the examples, you can also compute the cost $J$ as follows: \n",
        "$$J = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\large\\left(\\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right)  \\large  \\right) \\small \\tag{6}$$\n",
        "\n",
        "**Reminder**: The general methodology to build a Neural Network is to:\n",
        "    1. Define the neural network structure ( # of input units,  # of hidden units, etc). \n",
        "    2. Initialize the model's parameters\n",
        "    3. Loop:\n",
        "        - Implement forward propagation\n",
        "        - Compute loss\n",
        "        - Implement backward propagation to get the gradients\n",
        "        - Update parameters (gradient descent)\n",
        "\n",
        "You often build helper functions to compute steps 1-3 and then merge them into one function we call `nn_model()`. Once you've built `nn_model()` and learnt the right parameters, you can make predictions on new data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYtaEqHoNpPx"
      },
      "source": [
        "### 4.1 - Defining the neural network structure ####\n",
        "\n",
        "**Exercise**:\n",
        "\n",
        "Define three variables:\n",
        "    - n_x: the size of the input layer\n",
        "    - n_h: the size of the hidden layer (set this to 4) \n",
        "    - n_y: the size of the output layer\n",
        "\n",
        "**Hint**: Use shapes of X and Y to find n_x and n_y. Also, hard code the hidden layer size to be 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAbTVNNhNpPy"
      },
      "source": [
        "# GRADED FUNCTION: layer_sizes\n",
        "\n",
        "def layer_sizes(X, Y):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    X -- input dataset of shape (input size, number of examples)\n",
        "    Y -- labels of shape (output size, number of examples)\n",
        "    \n",
        "    Returns:\n",
        "    n_x -- the size of the input layer\n",
        "    n_h -- the size of the hidden layer\n",
        "    n_y -- the size of the output layer\n",
        "    \"\"\"\n",
        "    ### START CODE HERE ### (≈ 3 lines of code)\n",
        "    n_x = X.shape[0] # size of input layer\n",
        "    n_h = 4\n",
        "    n_y = Y.shape[1] # size of output layer\n",
        "    ### END CODE HERE ###\n",
        "    return (n_x, n_h, n_y)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf7mGRXhNpP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b65991d-7ff4-43a6-db1d-ef5306175440"
      },
      "source": [
        "X_assess, Y_assess = layer_sizes_test_case()\n",
        "(n_x, n_h, n_y) = layer_sizes(X_assess, Y_assess)\n",
        "print(\"The size of the input layer is: n_x = \" + str(n_x))\n",
        "print(\"The size of the hidden layer is: n_h = \" + str(n_h))\n",
        "print(\"The size of the output layer is: n_y = \" + str(n_y))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of the input layer is: n_x = 5\n",
            "The size of the hidden layer is: n_h = 4\n",
            "The size of the output layer is: n_y = 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG9JWtnMNpP3"
      },
      "source": [
        "**Expected Output** (these are not the sizes you will use for your network, they are just used to assess the function you've just coded).\n",
        "\n",
        "<table style=\"width:20%\">\n",
        "  <tr>\n",
        "    <td>**n_x**</td>\n",
        "    <td> 5 </td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>**n_h**</td>\n",
        "    <td> 4 </td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>**n_y**</td>\n",
        "    <td> 2 </td> \n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajeLyVSxNpP3"
      },
      "source": [
        "### 4.2 - Initialize the model's parameters ####\n",
        "\n",
        "**Exercise**: Implement the function `initialize_parameters()`.\n",
        "\n",
        "**Instructions**:\n",
        "- Make sure your parameters' sizes are right. Refer to the neural network figure above if needed.\n",
        "- You will initialize the weights matrices with random values. \n",
        "    - Use: `np.random.randn(a,b) * 0.01` to randomly initialize a matrix of shape (a,b).\n",
        "- You will initialize the bias vectors as zeros. \n",
        "    - Use: `np.zeros((a,b))` to initialize a matrix of shape (a,b) with zeros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEaPQPoDNpP4"
      },
      "source": [
        "# GRADED FUNCTION: initialize_parameters\n",
        "\n",
        "def initialize_parameters(n_x, n_h, n_y):\n",
        "    \"\"\"\n",
        "    Argument:\n",
        "    n_x -- size of the input layer\n",
        "    n_h -- size of the hidden layer\n",
        "    n_y -- size of the output layer\n",
        "    \n",
        "    Returns:\n",
        "    params -- python dictionary containing your parameters:\n",
        "                    W1 -- weight matrix of shape (n_h, n_x)\n",
        "                    b1 -- bias vector of shape (n_h, 1)\n",
        "                    W2 -- weight matrix of shape (n_y, n_h)\n",
        "                    b2 -- bias vector of shape (n_y, 1)\n",
        "    \"\"\"\n",
        "    \n",
        "    np.random.seed(2) # we set up a seed so that your output matches ours although the initialization is random.\n",
        "    \n",
        "    ### START CODE HERE ### (≈ 4 lines of code)\n",
        "    W1 = np.random.randn(n_h,n_x)*0.01\n",
        "    b1 = np.zeros((n_h,1))\n",
        "    W2 = np.random.randn(n_y,n_h)*0.01\n",
        "    b2 = np.zeros((n_y,1))\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    assert (W1.shape == (n_h, n_x))\n",
        "    assert (b1.shape == (n_h, 1))\n",
        "    assert (W2.shape == (n_y, n_h))\n",
        "    assert (b2.shape == (n_y, 1))\n",
        "    \n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2}\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTCtghDONpP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e32fc36-2acc-4390-cda3-526b4b9df31d"
      },
      "source": [
        "n_x, n_h, n_y = initialize_parameters_test_case()\n",
        "\n",
        "parameters = initialize_parameters(n_x, n_h, n_y)\n",
        "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
        "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
        "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
        "print(\"b2 = \" + str(parameters[\"b2\"]))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1 = [[-0.00416758 -0.00056267]\n",
            " [-0.02136196  0.01640271]\n",
            " [-0.01793436 -0.00841747]\n",
            " [ 0.00502881 -0.01245288]]\n",
            "b1 = [[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "W2 = [[-0.01057952 -0.00909008  0.00551454  0.02292208]]\n",
            "b2 = [[0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDzZha15NpP-"
      },
      "source": [
        "**Expected Output**:\n",
        "\n",
        "<table style=\"width:90%\">\n",
        "  <tr>\n",
        "    <td>**W1**</td>\n",
        "    <td> [[-0.00416758 -0.00056267]\n",
        " [-0.02136196  0.01640271]\n",
        " [-0.01793436 -0.00841747]\n",
        " [ 0.00502881 -0.01245288]] </td> \n",
        "  </tr>\n",
        "  \n",
        "  <tr>\n",
        "    <td>**b1**</td>\n",
        "    <td> [[ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]] </td> \n",
        "  </tr>\n",
        "  \n",
        "  <tr>\n",
        "    <td>**W2**</td>\n",
        "    <td> [[-0.01057952 -0.00909008  0.00551454  0.02292208]]</td> \n",
        "  </tr>\n",
        "  \n",
        "\n",
        "  <tr>\n",
        "    <td>**b2**</td>\n",
        "    <td> [[ 0.]] </td> \n",
        "  </tr>\n",
        "  \n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6Ja3SmTNpP-"
      },
      "source": [
        "### 4.3 - The Loop ####\n",
        "\n",
        "**Question**: Implement `forward_propagation()`.\n",
        "\n",
        "**Instructions**:\n",
        "- Look above at the mathematical representation of your classifier.\n",
        "- You can use the function `sigmoid()`. It is built-in (imported) in the notebook.\n",
        "- You can use the function `np.tanh()`. It is part of the numpy library.\n",
        "- The steps you have to implement are:\n",
        "    1. Retrieve each parameter from the dictionary \"parameters\" (which is the output of `initialize_parameters()`) by using `parameters[\"..\"]`.\n",
        "    2. Implement Forward Propagation. Compute $Z^{[1]}, A^{[1]}, Z^{[2]}$ and $A^{[2]}$ (the vector of all your predictions on all the examples in the training set).\n",
        "- Values needed in the backpropagation are stored in \"`cache`\". The `cache` will be given as an input to the backpropagation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-xqw6Z1NpP_"
      },
      "source": [
        "# GRADED FUNCTION: forward_propagation\n",
        "\n",
        "def forward_propagation(X, parameters):\n",
        "    \"\"\"\n",
        "    Argument:\n",
        "    X -- input data of size (n_x, m)\n",
        "    parameters -- python dictionary containing your parameters (output of initialization function)\n",
        "    \n",
        "    Returns:\n",
        "    A2 -- The sigmoid output of the second activation\n",
        "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\"\n",
        "    \"\"\"\n",
        "    # Retrieve each parameter from the dictionary \"parameters\"\n",
        "    ### START CODE HERE ### (≈ 4 lines of code)\n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Implement Forward Propagation to calculate A2 (probabilities)\n",
        "    ### START CODE HERE ### (≈ 4 lines of code)\n",
        "    Z1 = np.dot(W1, X) + b1\n",
        "    A1 = np.tanh(Z1)\n",
        "    Z2 = np.dot(W2, A1) + b2\n",
        "    A2 = sigmoid(Z2)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    assert(A2.shape == (1, X.shape[1]))\n",
        "    \n",
        "    cache = {\"Z1\": Z1,\n",
        "             \"A1\": A1,\n",
        "             \"Z2\": Z2,\n",
        "             \"A2\": A2}\n",
        "    \n",
        "    return A2, cache"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzErEfkPNpQB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f42dc3c8-7517-48e9-8cf0-d6d751849125"
      },
      "source": [
        "X_assess, parameters = forward_propagation_test_case()\n",
        "A2, cache = forward_propagation(X_assess, parameters)\n",
        "\n",
        "# Note: we use the mean here just to make sure that your output matches ours. \n",
        "print(np.mean(cache['Z1']) ,np.mean(cache['A1']),np.mean(cache['Z2']),np.mean(cache['A2']))\n",
        "\n",
        "print(\"\\nX_assess = \\n\", X_assess)\n",
        "print(\"\\nA2 = \\n\", A2)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.26281864019752443 0.09199904522700113 -1.3076660128732143 0.21287768171914198\n",
            "\n",
            "X_assess = \n",
            " [[ 1.62434536 -0.61175641 -0.52817175]\n",
            " [-1.07296862  0.86540763 -2.3015387 ]]\n",
            "\n",
            "A2 = \n",
            " [[0.21292656 0.21274673 0.21295976]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ3yxQX8NpQE"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style=\"width:50%\">\n",
        "  <tr>\n",
        "    <td> 0.262818640198 0.091999045227 -1.30766601287 0.212877681719 </td> \n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTATxsJfNpQE"
      },
      "source": [
        "Now that you have computed $A^{[2]}$ (in the Python variable \"`A2`\"), which contains $a^{[2](i)}$ for every example, you can compute the cost function as follows:\n",
        "\n",
        "$$J = - \\frac{1}{m} \\sum\\limits_{i = 1}^{m} \\large{(} \\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right) \\large{)} \\small\\tag{13}$$\n",
        "\n",
        "**Exercise**: Implement `compute_cost()` to compute the value of the cost $J$.\n",
        "\n",
        "**Instructions**:\n",
        "- There are many ways to implement the cross-entropy loss. To help you, we give you how we would have implemented\n",
        "$- \\sum\\limits_{i=0}^{m}  y^{(i)}\\log(a^{[2](i)})$:\n",
        "```python\n",
        "logprobs = np.multiply(np.log(A2),Y)\n",
        "cost = - np.sum(logprobs)                # no need to use a for loop!\n",
        "```\n",
        "\n",
        "(you can use either `np.multiply()` and then `np.sum()` or directly `np.dot()`).  \n",
        "Note that if you use `np.multiply` followed by `np.sum` the end result will be a type `float`, whereas if you use `np.dot`, the result will be a 2D numpy array.  We can use `np.squeeze()` to remove redundant dimensions (in the case of single float, this will be reduced to a zero-dimension array). We can cast the array as a type `float` using `float()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNOb0YuxNpQF"
      },
      "source": [
        "# GRADED FUNCTION: compute_cost\n",
        "\n",
        "def compute_cost(A2, Y, parameters):\n",
        "    \"\"\"\n",
        "    Computes the cross-entropy cost given in equation (13)\n",
        "    \n",
        "    Arguments:\n",
        "    A2 -- The sigmoid output of the second activation, of shape (1, number of examples)\n",
        "    Y -- \"true\" labels vector of shape (1, number of examples)\n",
        "    parameters -- python dictionary containing your parameters W1, b1, W2 and b2\n",
        "    [Note that the parameters argument is not used in this function, \n",
        "    but the auto-grader currently expects this parameter.\n",
        "    Future version of this notebook will fix both the notebook \n",
        "    and the auto-grader so that `parameters` is not needed.\n",
        "    For now, please include `parameters` in the function signature,\n",
        "    and also when invoking this function.]\n",
        "    \n",
        "    Returns:\n",
        "    cost -- cross-entropy cost given equation (13)\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    m = Y.shape[1] # number of example\n",
        "\n",
        "    # Compute the cross-entropy cost\n",
        "    ### START CODE HERE ### (≈ 2 lines of code)\n",
        "    logprobs = np.multiply(np.log(A2), Y) + np.multiply(np.log(1 - A2), 1 - Y)\n",
        "    cost = -np.sum(logprobs)/m\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    cost = float(np.squeeze(cost))  # makes sure cost is the dimension we expect. \n",
        "                                    # E.g., turns [[17]] into 17 \n",
        "    assert(isinstance(cost, float))\n",
        "    \n",
        "    return cost"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_av4cP3NpQH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5d12694-e570-4115-b05b-3dc0991f303e"
      },
      "source": [
        "A2, Y_assess, parameters = compute_cost_test_case()\n",
        "\n",
        "print(\"cost = \" + str(compute_cost(A2, Y_assess, parameters)))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cost = 0.6930587610394646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHezzlKnNpQJ"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style=\"width:20%\">\n",
        "  <tr>\n",
        "    <td>**cost**</td>\n",
        "    <td> 0.693058761... </td> \n",
        "  </tr>\n",
        "  \n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A3EnMP6NpQJ"
      },
      "source": [
        "Using the cache computed during forward propagation, you can now implement backward propagation.\n",
        "\n",
        "**Question**: Implement the function `backward_propagation()`.\n",
        "\n",
        "**Instructions**:\n",
        "Backpropagation is usually the hardest (most mathematical) part in deep learning. To help you, here again is the slide from the lecture on backpropagation. You'll want to use the six equations on the right of this slide, since you are building a vectorized implementation.  \n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1_clN2OvAht9yFe5TrTB0sJhP9LDhat81)\n",
        "\n",
        "\n",
        "\n",
        "<!--\n",
        "$\\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } = \\frac{1}{m} (a^{[2](i)} - y^{(i)})$\n",
        "\n",
        "$\\frac{\\partial \\mathcal{J} }{ \\partial W_2 } = \\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } a^{[1] (i) T} $\n",
        "\n",
        "$\\frac{\\partial \\mathcal{J} }{ \\partial b_2 } = \\sum_i{\\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)}}}$\n",
        "\n",
        "$\\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)} } =  W_2^T \\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } * ( 1 - a^{[1] (i) 2}) $\n",
        "\n",
        "$\\frac{\\partial \\mathcal{J} }{ \\partial W_1 } = \\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)} }  X^T $\n",
        "\n",
        "$\\frac{\\partial \\mathcal{J} _i }{ \\partial b_1 } = \\sum_i{\\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)}}}$\n",
        "\n",
        "- Note that $*$ denotes elementwise multiplication.\n",
        "- The notation you will use is common in deep learning coding:\n",
        "    - dW1 = $\\frac{\\partial \\mathcal{J} }{ \\partial W_1 }$\n",
        "    - db1 = $\\frac{\\partial \\mathcal{J} }{ \\partial b_1 }$\n",
        "    - dW2 = $\\frac{\\partial \\mathcal{J} }{ \\partial W_2 }$\n",
        "    - db2 = $\\frac{\\partial \\mathcal{J} }{ \\partial b_2 }$\n",
        "    \n",
        "!-->\n",
        "\n",
        "- Tips:\n",
        "    - To compute dZ1 you'll need to compute $g^{[1]'}(Z^{[1]})$. Since $g^{[1]}(.)$ is the tanh activation function, if $a = g^{[1]}(z)$ then $g^{[1]'}(z) = 1-a^2$. So you can compute \n",
        "    $g^{[1]'}(Z^{[1]})$ using `(1 - np.power(A1, 2))`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkTd0f7eNpQK"
      },
      "source": [
        "# GRADED FUNCTION: backward_propagation\n",
        "\n",
        "def backward_propagation(parameters, cache, X, Y):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation using the instructions above.\n",
        "    \n",
        "    Arguments:\n",
        "    parameters -- python dictionary containing our parameters \n",
        "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\".\n",
        "    X -- input data of shape (2, number of examples)\n",
        "    Y -- \"true\" labels vector of shape (1, number of examples)\n",
        "    \n",
        "    Returns:\n",
        "    grads -- python dictionary containing your gradients with respect to different parameters\n",
        "    \"\"\"\n",
        "    m = X.shape[1]\n",
        "    \n",
        "    # First, retrieve W1 and W2 from the dictionary \"parameters\".\n",
        "    ### START CODE HERE ### (≈ 2 lines of code)\n",
        "    W1 = parameters['W1']\n",
        "    W2 = parameters['W2']\n",
        "    ### END CODE HERE ###\n",
        "        \n",
        "    # Retrieve also A1 and A2 from dictionary \"cache\".\n",
        "    ### START CODE HERE ### (≈ 2 lines of code)\n",
        "    A1 = cache['A1']\n",
        "    A2 = cache['A2']\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Backward propagation: calculate dW1, db1, dW2, db2. \n",
        "    ### START CODE HERE ### (≈ 6 lines of code, corresponding to 6 equations on slide above)\n",
        "    dZ2 = A2 - Y\n",
        "    dW2 = np.dot(dZ2, A1.T)/m\n",
        "    db2 = np.sum(dZ2, axis = 1, keepdims = True)/m\n",
        "    dZ1 = np.dot(W2.T, dZ2)*(1 - np.power(A1, 2))\n",
        "    dW1 = np.dot(dZ1, X.T)/m\n",
        "    db1 = np.sum(dZ1, axis = 1, keepdims = True)/m\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    grads = {\"dW1\": dW1,\n",
        "             \"db1\": db1,\n",
        "             \"dW2\": dW2,\n",
        "             \"db2\": db2}\n",
        "    \n",
        "    return grads"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wcRPCEWNpQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc9dad59-cd72-4b98-d2b7-e60a13331673"
      },
      "source": [
        "parameters, cache, X_assess, Y_assess = backward_propagation_test_case()\n",
        "\n",
        "grads = backward_propagation(parameters, cache, X_assess, Y_assess)\n",
        "print (\"dW1 = \"+ str(grads[\"dW1\"]))\n",
        "print (\"db1 = \"+ str(grads[\"db1\"]))\n",
        "print (\"dW2 = \"+ str(grads[\"dW2\"]))\n",
        "print (\"db2 = \"+ str(grads[\"db2\"]))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dW1 = [[ 0.00301023 -0.00747267]\n",
            " [ 0.00257968 -0.00641288]\n",
            " [-0.00156892  0.003893  ]\n",
            " [-0.00652037  0.01618243]]\n",
            "db1 = [[ 0.00176201]\n",
            " [ 0.00150995]\n",
            " [-0.00091736]\n",
            " [-0.00381422]]\n",
            "dW2 = [[ 0.00078841  0.01765429 -0.00084166 -0.01022527]]\n",
            "db2 = [[-0.16655712]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVGzZWKjNpQO"
      },
      "source": [
        "**Expected output**:\n",
        "\n",
        "\n",
        "\n",
        "<table style=\"width:80%\">\n",
        "  <tr>\n",
        "    <td>**dW1**</td>\n",
        "    <td> [[ 0.00301023 -0.00747267]\n",
        " [ 0.00257968 -0.00641288]\n",
        " [-0.00156892  0.003893  ]\n",
        " [-0.00652037  0.01618243]] </td> \n",
        "  </tr>\n",
        "  \n",
        "  <tr>\n",
        "    <td>**db1**</td>\n",
        "    <td>  [[ 0.00176201]\n",
        " [ 0.00150995]\n",
        " [-0.00091736]\n",
        " [-0.00381422]] </td> \n",
        "  </tr>\n",
        "  \n",
        "  <tr>\n",
        "    <td>**dW2**</td>\n",
        "    <td> [[ 0.00078841  0.01765429 -0.00084166 -0.01022527]] </td> \n",
        "  </tr>\n",
        "  \n",
        "\n",
        "  <tr>\n",
        "    <td>**db2**</td>\n",
        "    <td> [[-0.16655712]] </td> \n",
        "  </tr>\n",
        "  \n",
        "</table>  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoXXHotqNpQO"
      },
      "source": [
        "**Question**: Implement the update rule. Use gradient descent. You have to use (dW1, db1, dW2, db2) in order to update (W1, b1, W2, b2).\n",
        "\n",
        "**General gradient descent rule**: $ \\theta = \\theta - \\alpha \\frac{\\partial J }{ \\partial \\theta }$ where $\\alpha$ is the learning rate and $\\theta$ represents a parameter.\n",
        "\n",
        "**Illustration**: The gradient descent algorithm with a good learning rate (converging) and a bad learning rate (diverging). Images courtesy of Adam Harley.\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1HPvxI2cjZmTRCQifxIpNUL7XKmegezov)\n",
        "\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1JOI8EajL9S6DzEnP2GgLfLJp4r_bUdc8)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drW_h081NpQP"
      },
      "source": [
        "# GRADED FUNCTION: update_parameters\n",
        "\n",
        "def update_parameters(parameters, grads, learning_rate = 1.2):\n",
        "    \"\"\"\n",
        "    Updates parameters using the gradient descent update rule given above\n",
        "    \n",
        "    Arguments:\n",
        "    parameters -- python dictionary containing your parameters \n",
        "    grads -- python dictionary containing your gradients \n",
        "    \n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your updated parameters \n",
        "    \"\"\"\n",
        "    # Retrieve each parameter from the dictionary \"parameters\"\n",
        "    ### START CODE HERE ### (≈ 4 lines of code)\n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Retrieve each gradient from the dictionary \"grads\"\n",
        "    ### START CODE HERE ### (≈ 4 lines of code)\n",
        "    dW1 = grads['dW1']\n",
        "    db1 = grads['db1']\n",
        "    dW2 = grads['dW2']\n",
        "    db2 = grads['db2']\n",
        "    ## END CODE HERE ###\n",
        "    \n",
        "    # Update rule for each parameter\n",
        "    ### START CODE HERE ### (≈ 4 lines of code)\n",
        "    W1 =  W1 - learning_rate*dW1\n",
        "    b1 = b1 - learning_rate*db1\n",
        "    W2 = W2 - learning_rate*dW2\n",
        "    b2 = b2 - learning_rate*db2\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2}\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "96sqkwsGNpQR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a386d773-4bff-45de-d531-51087a90edae"
      },
      "source": [
        "parameters, grads = update_parameters_test_case()\n",
        "parameters = update_parameters(parameters, grads)\n",
        "\n",
        "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
        "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
        "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
        "print(\"b2 = \" + str(parameters[\"b2\"]))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1 = [[-0.00643025  0.01936718]\n",
            " [-0.02410458  0.03978052]\n",
            " [-0.01653973 -0.02096177]\n",
            " [ 0.01046864 -0.05990141]]\n",
            "b1 = [[-1.02420756e-06]\n",
            " [ 1.27373948e-05]\n",
            " [ 8.32996807e-07]\n",
            " [-3.20136836e-06]]\n",
            "W2 = [[-0.01041081 -0.04463285  0.01758031  0.04747113]]\n",
            "b2 = [[0.00010457]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4u4C--eNpQT"
      },
      "source": [
        "**Expected Output**:\n",
        "\n",
        "\n",
        "<table style=\"width:80%\">\n",
        "  <tr>\n",
        "    <td>**W1**</td>\n",
        "    <td> [[-0.00643025  0.01936718]\n",
        " [-0.02410458  0.03978052]\n",
        " [-0.01653973 -0.02096177]\n",
        " [ 0.01046864 -0.05990141]]</td> \n",
        "  </tr>\n",
        "  \n",
        "  <tr>\n",
        "    <td>**b1**</td>\n",
        "    <td> [[ -1.02420756e-06]\n",
        " [  1.27373948e-05]\n",
        " [  8.32996807e-07]\n",
        " [ -3.20136836e-06]]</td> \n",
        "  </tr>\n",
        "  \n",
        "  <tr>\n",
        "    <td>**W2**</td>\n",
        "    <td> [[-0.01041081 -0.04463285  0.01758031  0.04747113]] </td> \n",
        "  </tr>\n",
        "  \n",
        "\n",
        "  <tr>\n",
        "    <td>**b2**</td>\n",
        "    <td> [[ 0.00010457]] </td> \n",
        "  </tr>\n",
        "  \n",
        "</table>  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6KuITv7NpQT"
      },
      "source": [
        "### 4.4 - Integrate parts 4.1, 4.2 and 4.3 in nn_model() ####\n",
        "\n",
        "**Question**: Build your neural network model in `nn_model()`.\n",
        "\n",
        "**Instructions**: The neural network model has to use the previous functions in the right order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgvZA4WpNpQU"
      },
      "source": [
        "# GRADED FUNCTION: nn_model\n",
        "\n",
        "def nn_model(X, Y, n_h, num_iterations = 10000, print_cost=False):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    X -- dataset of shape (2, number of examples)\n",
        "    Y -- labels of shape (1, number of examples)\n",
        "    n_h -- size of the hidden layer\n",
        "    num_iterations -- Number of iterations in gradient descent loop\n",
        "    print_cost -- if True, print the cost every 1000 iterations\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
        "    \"\"\"\n",
        "    \n",
        "    np.random.seed(3)\n",
        "    n_x = layer_sizes(X, Y)[0]\n",
        "    n_y = layer_sizes(X, Y)[2]\n",
        "    \n",
        "    # Initialize parameters\n",
        "    ### START CODE HERE ### (≈ 1 line of code)\n",
        "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Loop (gradient descent)\n",
        "\n",
        "    for i in range(0, num_iterations):\n",
        "         \n",
        "        ### START CODE HERE ### (≈ 4 lines of code)\n",
        "        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n",
        "        A2, cache = forward_propagation(X, parameters)\n",
        "        \n",
        "        # Cost function. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\n",
        "        cost = compute_cost(A2, Y, parameters)\n",
        " \n",
        "        # Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n",
        "        grads = backward_propagation(parameters, cache, X, Y)\n",
        " \n",
        "        # Gradient descent parameter update. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n",
        "        parameters = update_parameters(parameters, grads)\n",
        "\n",
        "        \n",
        "        ### END CODE HERE ###\n",
        "        \n",
        "        # Print the cost every 1000 iterations\n",
        "        if print_cost and i % 1000 == 0:\n",
        "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
        "\n",
        "    return parameters"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofJDyXZSNpQW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "96b41c0a-08b6-4896-9f1d-a0e4784381d1"
      },
      "source": [
        "X_assess, Y_assess = nn_model_test_case()\n",
        "parameters = nn_model(X_assess, Y_assess, 4, num_iterations=10000, print_cost=True)\n",
        "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
        "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
        "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
        "print(\"b2 = \" + str(parameters[\"b2\"]))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-1f4aa99c03a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_assess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_assess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_model_test_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_assess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_assess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_cost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W1 = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"b1 = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W2 = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-960e1719c0de>\u001b[0m in \u001b[0;36mnn_model\u001b[0;34m(X, Y, n_h, num_iterations, print_cost)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m### START CODE HERE ### (≈ 4 lines of code)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mA2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Cost function. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-58e0c592d3ac>\u001b[0m in \u001b[0;36mforward_propagation\u001b[0;34m(X, parameters)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     cache = {\"Z1\": Z1,\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrviMmCLNpQZ"
      },
      "source": [
        "**Expected Output**:\n",
        "\n",
        "<table style=\"width:90%\">\n",
        "\n",
        "<tr> \n",
        "    <td> \n",
        "        **cost after iteration 0**\n",
        "    </td>\n",
        "    <td> \n",
        "        0.692739\n",
        "    </td>\n",
        "</tr>\n",
        "\n",
        "<tr> \n",
        "    <td> \n",
        "        <center> $\\vdots$ </center>\n",
        "    </td>\n",
        "    <td> \n",
        "        <center> $\\vdots$ </center>\n",
        "    </td>\n",
        "</tr>\n",
        "\n",
        "  <tr>\n",
        "    <td>**W1**</td>\n",
        "    <td> [[-0.65848169  1.21866811]\n",
        " [-0.76204273  1.39377573]\n",
        " [ 0.5792005  -1.10397703]\n",
        " [ 0.76773391 -1.41477129]]</td> \n",
        "  </tr>\n",
        "  \n",
        "  <tr>\n",
        "    <td>**b1**</td>\n",
        "    <td> [[ 0.287592  ]\n",
        " [ 0.3511264 ]\n",
        " [-0.2431246 ]\n",
        " [-0.35772805]] </td> \n",
        "  </tr>\n",
        "  \n",
        "  <tr>\n",
        "    <td>**W2**</td>\n",
        "    <td> [[-2.45566237 -3.27042274  2.00784958  3.36773273]] </td> \n",
        "  </tr>\n",
        "  \n",
        "\n",
        "  <tr>\n",
        "    <td>**b2**</td>\n",
        "    <td> [[ 0.20459656]] </td> \n",
        "  </tr>\n",
        "  \n",
        "</table>  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC5AyCPyNpQa"
      },
      "source": [
        "### 4.5 Predictions\n",
        "\n",
        "**Question**: Use your model to predict by building predict().\n",
        "Use forward propagation to predict results.\n",
        "\n",
        "**Reminder**: predictions = $y_{prediction} = \\mathbb 1 \\text{{activation > 0.5}} = \\begin{cases}\n",
        "      1 & \\text{if}\\ activation > 0.5 \\\\\n",
        "      0 & \\text{otherwise}\n",
        "    \\end{cases}$  \n",
        "    \n",
        "As an example, if you would like to set the entries of a matrix X to 0 and 1 based on a threshold you would do: ```X_new = (X > threshold)```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdTa_E59NpQa"
      },
      "source": [
        "# GRADED FUNCTION: predict\n",
        "\n",
        "def predict(parameters, X):\n",
        "    \"\"\"\n",
        "    Using the learned parameters, predicts a class for each example in X\n",
        "    \n",
        "    Arguments:\n",
        "    parameters -- python dictionary containing your parameters \n",
        "    X -- input data of size (n_x, m)\n",
        "    \n",
        "    Returns\n",
        "    predictions -- vector of predictions of our model (red: 0 / blue: 1)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.\n",
        "    ### START CODE HERE ### (≈ 2 lines of code)\n",
        "    A2, cache = forward_propagation(X, parameters)\n",
        "    predictions = np.round(A2)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return predictions"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lr9Qe1kiNpQc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d17b2d4-8b3d-4c80-c8e0-e43a2eb2f669"
      },
      "source": [
        "parameters, X_assess = predict_test_case()\n",
        "\n",
        "predictions = predict(parameters, X_assess)\n",
        "print(\"predictions mean = \" + str(np.mean(predictions)))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions mean = 0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhgIFqRLNpQf"
      },
      "source": [
        "**Expected Output**: \n",
        "\n",
        "\n",
        "<table style=\"width:40%\">\n",
        "  <tr>\n",
        "    <td>**predictions mean**</td>\n",
        "    <td> 0.666666666667 </td> \n",
        "  </tr>\n",
        "  \n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEIXmLWoNpQf"
      },
      "source": [
        "It is time to run the model and see how it performs on a planar dataset. Run the following code to test your model with a single hidden layer of $n_h$ hidden units."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "afUH_4MZNpQf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "5cdbd611-c640-4f06-cc71-2447bcbcec51"
      },
      "source": [
        "# Build a model with a n_h-dimensional hidden layer\n",
        "parameters = nn_model(X, Y, n_h = 4, num_iterations = 10000, print_cost=True)\n",
        "\n",
        "# Plot the decision boundary\n",
        "plot_decision_boundary(lambda x: predict(parameters, x.T), X, Y)\n",
        "plt.title(\"Decision Boundary for hidden layer size \" + str(4))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-11bad20c9992>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Build a model with a n_h-dimensional hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_cost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Plot the decision boundary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplot_decision_boundary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-41f8e6ceea69>\u001b[0m in \u001b[0;36mnn_model\u001b[0;34m(X, Y, n_h, num_iterations, print_cost)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m### START CODE HERE ### (≈ 4 lines of code)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mA2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Cost function. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-58e0c592d3ac>\u001b[0m in \u001b[0;36mforward_propagation\u001b[0;34m(X, parameters)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     cache = {\"Z1\": Z1,\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM6EWjPeNpQh"
      },
      "source": [
        "**Expected Output**:\n",
        "\n",
        "<table style=\"width:40%\">\n",
        "  <tr>\n",
        "    <td>**Cost after iteration 9000**</td>\n",
        "    <td> 0.218607 </td> \n",
        "  </tr>\n",
        "  \n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P3YmbX7NpQi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d71e88a5-4e8e-47fe-83eb-c1fc6f8e7e50"
      },
      "source": [
        "# Print accuracy\n",
        "predictions = predict(parameters, X)\n",
        "print ('Accuracy: %d' % float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100) + '%')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 54%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_GR_51hNpQk"
      },
      "source": [
        "**Expected Output**: \n",
        "\n",
        "<table style=\"width:15%\">\n",
        "  <tr>\n",
        "    <td>**Accuracy**</td>\n",
        "    <td> 90% </td> \n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoriZiSPNpQk"
      },
      "source": [
        "Accuracy is really high compared to Logistic Regression. The model has learnt the leaf patterns of the flower! Neural networks are able to learn even highly non-linear decision boundaries, unlike logistic regression. \n",
        "\n",
        "Now, let's try out several hidden layer sizes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChR0ai2nNpQl"
      },
      "source": [
        "### 4.6 - Tuning hidden layer size (optional/ungraded exercise) ###\n",
        "\n",
        "Run the following code. It may take 1-2 minutes. You will observe different behaviors of the model for various hidden layer sizes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "lAGjif-FNpQl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "outputId": "3c2eb78d-0e9f-48e2-b148-f4b397fabf67"
      },
      "source": [
        "# This may take about 2 minutes to run\n",
        "\n",
        "plt.figure(figsize=(16, 32))\n",
        "hidden_layer_sizes = [1, 2, 3, 4, 5, 20, 50]\n",
        "for i, n_h in enumerate(hidden_layer_sizes):\n",
        "    plt.subplot(5, 2, i+1)\n",
        "    plt.title('Hidden Layer of size %d' % n_h)\n",
        "    parameters = nn_model(X, Y, n_h, num_iterations = 5000)\n",
        "    plot_decision_boundary(lambda x: predict(parameters, x.T), X, Y)\n",
        "    predictions = predict(parameters, X)\n",
        "    accuracy = float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100)\n",
        "    print (\"Accuracy for {} hidden units: {} %\".format(n_h, accuracy))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-79d8354e3077>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Hidden Layer of size %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mplot_decision_boundary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-41f8e6ceea69>\u001b[0m in \u001b[0;36mnn_model\u001b[0;34m(X, Y, n_h, num_iterations, print_cost)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m### START CODE HERE ### (≈ 4 lines of code)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mA2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Cost function. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-58e0c592d3ac>\u001b[0m in \u001b[0;36mforward_propagation\u001b[0;34m(X, parameters)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     cache = {\"Z1\": Z1,\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x2304 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npyBdvVyNpQn"
      },
      "source": [
        "**Interpretation**:\n",
        "- The larger models (with more hidden units) are able to fit the training set better, until eventually the largest models overfit the data. \n",
        "- The best hidden layer size seems to be around n_h = 5. Indeed, a value around here seems to  fits the data well without also incurring noticeable overfitting.\n",
        "- You will also learn later about regularization, which lets you use very large models (such as n_h = 50) without much overfitting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2RCkEwqNpQo"
      },
      "source": [
        "**Optional questions**:\n",
        "\n",
        "**Note**: Remember to submit the assignment by clicking the blue \"Submit Assignment\" button at the upper-right. \n",
        "\n",
        "Some optional/ungraded questions that you can explore if you wish: \n",
        "- What happens when you change the tanh activation for a sigmoid activation or a ReLU activation?\n",
        "- Play with the learning_rate. What happens?\n",
        "- What if we change the dataset? (See part 5 below!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpZSUtZMNpQo"
      },
      "source": [
        "<font color='blue'>\n",
        "**You've learnt to:**\n",
        "- Build a complete neural network with a hidden layer\n",
        "- Make a good use of a non-linear unit\n",
        "- Implemented forward propagation and backpropagation, and trained a neural network\n",
        "- See the impact of varying the hidden layer size, including overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoF-f1YhNpQo"
      },
      "source": [
        "Nice work! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxvHQ3fANpQp"
      },
      "source": [
        "## 5) Performance on other datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9oPKX_cNpQp"
      },
      "source": [
        "If you want, you can rerun the whole notebook (minus the dataset part) for each of the following datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "KXHfDp4DNpQq"
      },
      "source": [
        "# Datasets\n",
        "noisy_circles, noisy_moons, blobs, gaussian_quantiles, no_structure = load_extra_datasets()\n",
        "\n",
        "datasets = {\"noisy_circles\": noisy_circles,\n",
        "            \"noisy_moons\": noisy_moons,\n",
        "            \"blobs\": blobs,\n",
        "            \"gaussian_quantiles\": gaussian_quantiles}\n",
        "\n",
        "### START CODE HERE ### (choose your dataset)\n",
        "dataset = \"noisy_moons\"\n",
        "### END CODE HERE ###\n",
        "\n",
        "X, Y = datasets[dataset]\n",
        "X, Y = X.T, Y.reshape(1, Y.shape[0])\n",
        "\n",
        "# make blobs binary\n",
        "if dataset == \"blobs\":\n",
        "    Y = Y%2\n",
        "\n",
        "# Visualize the data\n",
        "plt.scatter(X[0, :], X[1, :], c=Y, s=40, cmap=plt.cm.Spectral);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMS3KIbkSsXI"
      },
      "source": [
        "plt.figure(figsize=(16, 32))\n",
        "hidden_layer_sizes = [1, 2, 3, 4, 5, 20, 50]\n",
        "for i, n_h in enumerate(hidden_layer_sizes):\n",
        "    plt.subplot(5, 2, i+1)\n",
        "    plt.title('Hidden Layer of size %d' % n_h)\n",
        "    parameters = nn_model(X, Y, n_h, num_iterations = 5000)\n",
        "    plot_decision_boundary(lambda x: predict(parameters, x.T), X, Y)\n",
        "    predictions = predict(parameters, X)\n",
        "    accuracy = float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100)\n",
        "    print (\"Accuracy for {} hidden units: {} %\".format(n_h, accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0KMNDXXNpQs"
      },
      "source": [
        "Congrats on finishing this Programming Assignment!\n",
        "\n",
        "Reference:\n",
        "- http://scs.ryerson.ca/~aharley/neural-networks/\n",
        "- http://cs231n.github.io/neural-networks-case-study/"
      ]
    }
  ]
}